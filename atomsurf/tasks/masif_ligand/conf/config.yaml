defaults:
  - _self_
  - blocks_zoo
  - encoder: debug
  - dataset: vanilla
  #  - dataset@trainset: [ masif_ligand_hmr ]
  #  - dataset@valset: [ masif_ligand_hmr ]
  #  - dataset@testset: [ masif_ligand_hmr ]
  - optimizer: adam
  - scheduler: reduce_lr_on_plateau
  - override hydra/job_logging: colorlog
  - override hydra/hydra_logging: colorlog

hydra:
  job:
    chdir: False

# general params
seed: 2024
run_name: default
out_dir: ../../../outputs/masif_ligand/out_dir
test_freq: 5
epochs: 100
device: 0
log_dir: "./"
path_model: "version_x/checkpoints/last.ckpt"

# loader params
loader:
  num_workers: 2
  batch_size: 8
  pin_memory: False
  prefetch_factor: 2
  shuffle: true

train:
  save_top_k: 2
  early_stoping_patience: 100
  accumulate_grad_batches: 1
  val_check_interval: 1.0
  check_val_every_n_epoch: 1
  limit_train_batches: 1.0
  limit_val_batches: 1.0
  limit_test_batches: 1.0
  # gradient clipping
  gradient_clip_val: 1.0
  deterministic: False
  # # epochs and batch_size
  max_steps: -1
  auto_lr_find: False
  log_every_n_steps: 50
  # # detect NaNs
  detect_anomaly: False
  # # debugging
  overfit_batches: 0
  to_monitor: accuracy_balanced/val

cfg_surface:
  use_surfaces: true
  use_whole_surfaces: False
  #  data_dir: ../../../data/masif_ligand/surf_full
  data_dir: ../../../data/masif_ligand/surf_ours
  feat_keys: 'all'
  oh_keys: 'all'

# python train.py 'cfg_graph.feat_keys=[hphobs]' 'cfg_graph.oh_keys=[amino_types]' cfg_graph.use_esm=True
cfg_graph:
  use_graphs: true
  data_dir: ../../../data/masif_ligand/rgraph
  feat_keys: 'all'
  oh_keys: 'all'
  esm_dir: ../../../data/masif_ligand/esm
  use_esm: false

#cfg_graph:
#  use_graphs: true
#  data_dir: ../../../data/masif_ligand/agraph
#  feat_keys: 'all'
#  oh_keys: 'all'
#  esm_dir: ../../../data/masif_ligand/esm
#  use_esm: false

cfg_head:
  encoded_dims: 12
  output_dims: 7
